{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score, cross_val_predict, validation_curve\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from numpy import nan\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "plt.rcParams['figure.figsize'] = (30,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the dataset and assigning column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n",
      "(16281, 15)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('adult.csv', header=None, names=[\"age\", \"wclass\", \"fnlwgt\", \"education\", \"education-num\", \"mstatus\", \\\n",
    "                                                 \"occ\", \"relationship\", \"race\", \"sex\", \"capgain\", \"caploss\", \\\n",
    "                                                  \"hperweek\", \"country\", \"class\"])\n",
    "df_test = pd.read_csv('adult.test.csv', header=None, names=[\"age\", \"wclass\", \"fnlwgt\", \"education\", \"education-num\", \"mstatus\", \\\n",
    "                                                 \"occ\", \"relationship\", \"race\", \"sex\", \"capgain\", \"caploss\", \\\n",
    "                                                  \"hperweek\", \"country\", \"class\"])\n",
    "print df_train.shape\n",
    "print df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age              0\n",
       "wclass           0\n",
       "fnlwgt           0\n",
       "education        0\n",
       "education-num    0\n",
       "mstatus          0\n",
       "occ              0\n",
       "relationship     0\n",
       "race             0\n",
       "sex              0\n",
       "capgain          0\n",
       "caploss          0\n",
       "hperweek         0\n",
       "country          0\n",
       "class            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values could be there in other ways. One of the most common ways is '?'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat adult.csv | grep '?' | wc -l\n",
    "#cat adult.test.csv | grep '?' | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the output as 2399 and 1221, which are exactly the number of missing values given at http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names. Hence these are the only missing values. We replace them with nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 0\n",
      "wclass           1836\n",
      "fnlwgt              0\n",
      "education           0\n",
      "education-num       0\n",
      "mstatus             0\n",
      "occ              1843\n",
      "relationship        0\n",
      "race                0\n",
      "sex                 0\n",
      "capgain             0\n",
      "caploss             0\n",
      "hperweek            0\n",
      "country           583\n",
      "class               0\n",
      "dtype: int64\n",
      "\n",
      "age                0\n",
      "wclass           963\n",
      "fnlwgt             0\n",
      "education          0\n",
      "education-num      0\n",
      "mstatus            0\n",
      "occ              966\n",
      "relationship       0\n",
      "race               0\n",
      "sex                0\n",
      "capgain            0\n",
      "caploss            0\n",
      "hperweek           0\n",
      "country          274\n",
      "class              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.replace({' ?':nan})\n",
    "print df_train.isnull().sum()\n",
    "df_test = df_test.replace({' ?':nan})\n",
    "print \"\\n\", df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out how to replace missing values, lets look at distribution of values of each \"missing value\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Private             22696\n",
      " Self-emp-not-inc     2541\n",
      " Local-gov            2093\n",
      "Name: wclass, dtype: int64\n",
      "\n",
      " Prof-specialty     4140\n",
      " Craft-repair       4099\n",
      " Exec-managerial    4066\n",
      "Name: occ, dtype: int64\n",
      "\n",
      " United-States    29170\n",
      " Mexico             643\n",
      " Philippines        198\n",
      "Name: country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df_train['wclass'].value_counts().head(3)\n",
    "print \"\\n\", df_train['occ'].value_counts().head(3)\n",
    "print \"\\n\", df_train['country'].value_counts().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For wclass and country, it seems ok to replace it by the mode - since the probability of that value being the mode is high. (Ideally, if it is greater than our accuracy, we should be good). 'Private' is 70% of training, country is '90%'. We can also look at how much each variable is contributing to the separability of the classes by plotting a scatter matrix. For now, avoid premature optimization, we'll just replace it by mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['wclass','occ','country']\n",
    "df_train[cols] = df_train[cols].fillna(df_train.mode().iloc[0])\n",
    "df_test[cols] = df_test[cols].fillna(df_train.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll transform the categorical features to numerical. The features which need to be transformed are 'wclass', 'mstatus', 'occ', 'relationship', 'race', 'sex', 'country', 'education' and 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wclass  mstatus  occ  relationship  race  sex  country  education  class\n",
      "0     6.0      4.0  0.0           1.0   4.0  1.0     38.0        9.0    0.0\n",
      "1     5.0      2.0  3.0           0.0   4.0  1.0     38.0        9.0    0.0\n",
      "2     3.0      0.0  5.0           1.0   4.0  1.0     38.0       11.0    0.0\n",
      "3     3.0      2.0  5.0           0.0   2.0  1.0     38.0        1.0    0.0\n",
      "4     3.0      2.0  9.0           5.0   2.0  0.0      4.0        9.0    0.0\n",
      "   wclass  mstatus   occ  relationship  race  sex  country  education  class\n",
      "0     3.0      4.0   6.0           3.0   2.0  1.0     38.0        1.0    0.0\n",
      "1     3.0      2.0   4.0           0.0   4.0  1.0     38.0       11.0    0.0\n",
      "2     1.0      2.0  10.0           0.0   4.0  1.0     38.0        7.0    1.0\n",
      "3     3.0      2.0   6.0           0.0   2.0  1.0     38.0       15.0    1.0\n",
      "4     3.0      4.0   9.0           3.0   4.0  0.0     38.0       15.0    0.0\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['wclass', 'mstatus', 'occ', 'relationship', 'race', 'sex', 'country', 'education', 'class']\n",
    "categorical_values_train = np.array(df_train[categorical_columns])\n",
    "categorical_values_test = np.array(df_test[categorical_columns])\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(categorical_values_train[:,0]) \n",
    "data_train = le.transform(categorical_values_train[:,0])\n",
    "data_test = le.transform(categorical_values_test[:,0])\n",
    "for i in range(1, categorical_values_train.shape[1]):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(categorical_values_train[:,i])\n",
    "    data_train = np.column_stack((data_train, le.transform(categorical_values_train[:,i])))\n",
    "    data_test = np.column_stack((data_test, le.transform(categorical_values_test[:,i])))\n",
    "\n",
    "df_train_new = pd.DataFrame(data_train.astype(float), columns=categorical_columns)\n",
    "df_test_new = pd.DataFrame(data_test.astype(float), columns=categorical_columns)\n",
    "print df_train_new.head()\n",
    "print df_test_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these, 'Education' and 'class' are features which don't require farther transformation (since it makes sense to preserve the ordinality of education, and class is something which is binray valued). For the rest, we will use onehotencoder to transform them to a non ordinal form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non_ordinal_columns = ['wclass', 'mstatus', 'occ', 'relationship', 'race', 'sex', 'country']\n",
    "non_ordinal_values_train = np.array(df_train_new[non_ordinal_columns])\n",
    "non_ordinal_values_test = np.array(df_test_new[non_ordinal_columns])\n",
    "ordinal_columns = ['education', 'class']\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(non_ordinal_values_train)\n",
    "\n",
    "data_train = enc.transform(non_ordinal_values_train)\n",
    "data_test = enc.transform(non_ordinal_values_test)\n",
    "\n",
    "cols = [non_ordinal_columns[i] + '_' + str(j) for i in range(0,len(non_ordinal_columns)) for j in range(0,enc.n_values_[i]) ]\n",
    "df_train_new2 = pd.DataFrame(data_train.toarray(),columns=cols)\n",
    "df_test_new2 = pd.DataFrame(data_test.toarray(),columns=cols)\n",
    "\n",
    "numerical_cols = ['age', 'fnlwgt', 'education-num', 'capgain', 'caploss', 'hperweek']\n",
    "df_train_cleaned = pd.concat([df_train_new2, df_train_new[ordinal_columns], df_train[numerical_cols]], axis=1)\n",
    "df_test_cleaned = pd.concat([df_test_new2, df_test_new[ordinal_columns], df_test[numerical_cols]], axis=1)\n",
    "print df_train_cleaned.shape\n",
    "print df_test_cleaned.shape\n",
    "print df_train_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Now, we normalize our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train_cleaned.drop('class', 1)\n",
    "y_train = df_train_cleaned['class']\n",
    "x_test = df_test_cleaned.drop('class', 1)\n",
    "y_test = df_test_cleaned['class']\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_norm = scaler.transform(x_train)\n",
    "x_test_norm = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 90)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
